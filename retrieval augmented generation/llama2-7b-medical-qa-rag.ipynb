{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "umM-rU8tGa4v"
      },
      "source": [
        "# Retrieval Augmented Generation for Medical Question-Answering with Llama-2-7b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2HoCnUasGa4x"
      },
      "source": [
        "In this notebook, we harness the Llama-2-7b model for medical question-answering. Using the Retrieval Augmented Generation (RAG) approach, we merge the inherent knowledge of Llama-2-7b with a curated medical knowledge base. Our strategy incorporates dense and sparse embeddings from MiniLM and Splade, respectively, facilitating precise, relevant, and non-hallucinated responses. With the aid of SageMaker and Pinecone, we present a seamless pipeline for embedding, retrieval, and insightful text generation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![llama2-7b-medical-qa-rag](../assets/img/llama2-7b-medical-qa-rag.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVqqgv7CGa4x",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "79daaf8a-adf5-42b4-9812-9b6d89bd292d",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "    sagemaker==2.173.0 \\\n",
        "    pinecone-client==2.2.1 \\\n",
        "    ipywidgets==7.0.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hzeSGel4Ga4z"
      },
      "source": [
        "## Deploy Llama-2-7b in SageMaker JumpStart"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eJjSq0OiGa40"
      },
      "source": [
        "Meta developed and publicly released the Llama 2 family of large language models (LLMs), a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama-2-Chat, are optimized for dialogue use cases. Llama-2-Chat models outperform open-source chat models on most benchmarks we tested, and in our human evaluations for helpfulness and safety, are on par with some popular closed-source models like ChatGPT and PaLM. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama-2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.\n",
        "\n",
        "Model Developers Meta AI\n",
        "\n",
        "Variations Llama 2 comes in a range of parameter sizes — 7B, 13B, and 70B — as well as pretrained and fine-tuned variations.\n",
        "\n",
        "Input Models input text only.\n",
        "\n",
        "Output Models generate text only.\n",
        "\n",
        "Model Architecture Llama 2 is an auto-regressive language optimized transformer. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.\n",
        "\n",
        "***\n",
        "This model supports the following inference payload parameters:\n",
        "\n",
        "* **max_new_tokens:** Model generates text until the output length (excluding the input context length) reaches max_new_tokens. If specified, it must be a positive integer.\n",
        "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
        "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
        "* **return_full_text:** If True, input text will be part of the output generated text. If specified, it must be boolean. The default value for it is False.\n",
        "\n",
        "You may specify any subset of the parameters mentioned above while invoking an endpoint.\n",
        "\n",
        "**NOTE**: If `max_new_tokens` is not defined, the model may generate up to the maximum total tokens allowed, which is 4K for these models. This may result in endpoint query timeout errors, so it is recommended to set `max_new_tokens` when possible. For 7B, 13B, and 70B models, we recommend to set `max_new_tokens` no greater than 1500, 1000, and 500 respectively, while keeping the total number of tokens less than 4K.\n",
        "\n",
        "**NOTE**: In order to support a 4k context length, this model has restricted query payloads to only utilize a batch size of 1. Payloads with larger batch sizes will receive an endpoint error prior to inference.\n",
        "***"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cQjwldLkGa41"
      },
      "source": [
        "## Ask a question to LLM with and without providing the context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gqC4gkiGa41",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udcgLwJdGa42",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def create_payload(question):\n",
        "    prompts = [question]\n",
        "    payloads = []\n",
        "    for prompt in prompts:\n",
        "        payloads.append(\n",
        "            {\n",
        "                \"inputs\": prompt,\n",
        "                \"parameters\": {\"max_new_tokens\": 10, \"top_p\": 0.9, \"temperature\": 0.3, \"return_full_text\": False},\n",
        "            }\n",
        "        )\n",
        "    return payloads[0]\n",
        "\n",
        "endpoint_name = 'jumpstart-dft-meta-textgeneration-llama-2-7b'\n",
        "\n",
        "def query_llama2_7b_endpoint(payload):\n",
        "    client = boto3.client(\"sagemaker-runtime\")\n",
        "    response = client.invoke_endpoint(\n",
        "        EndpointName=endpoint_name,\n",
        "        ContentType=\"application/json\",\n",
        "        Body=json.dumps(payload),\n",
        "        CustomAttributes=\"accept_eula=true\",\n",
        "    )\n",
        "    response = response[\"Body\"].read().decode(\"utf8\")\n",
        "    response = json.loads(response)\n",
        "    return response[0]['generation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l99F9KmBGa42",
        "outputId": "a764be86-a007-4a97-aebb-c0c4b33c7c7c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Which lace plant produces perforations in its leaves through PCD?\n",
            "\n",
            "A. Mimosa pudica\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question = \"Which lace plant produces perforations in its leaves through PCD?\"\n",
        "payload = create_payload(question)\n",
        "query_response = query_llama2_7b_endpoint(payload)\n",
        "print(payload[\"inputs\"])\n",
        "print(query_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP-f_2clGa43",
        "tags": []
      },
      "outputs": [],
      "source": [
        "context = \"\"\"Programmed cell death (PCD) is the regulated death of cells within an organism.\n",
        "The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD.\n",
        "The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing\n",
        "areoles. PCD occurs in the cells at the center of these areoles and progresses outwards,\n",
        "stopping approximately five cells from the vasculature.  The possible importance of mitochondrial\n",
        "permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo\n",
        "cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly\n",
        "lower number of perforations compared to controls, and that displayed mitochondrial dynamics\n",
        "similar to that of non-PCD cells.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUjoNYRxGa44",
        "outputId": "60ee6cca-977d-48a0-886f-554d960e24bd",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Aponogeton madagascariensis\\n'"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_template = \"\"\"Answer the following QUESTION based on the CONTEXT given.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\"\n",
        "\n",
        "text_input = prompt_template.replace(\"{context}\", context).replace(\"{question}\", question)\n",
        "payload = create_payload(text_input)\n",
        "query_response = query_llama2_7b_endpoint(payload)\n",
        "query_response"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxf7OC88Ga45",
        "tags": []
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgbPjWqvGa46",
        "outputId": "04fe94f1-becb-4090-e7c6-4b10a2bc6ad3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8b5cd8dcfc6a4593942acc862ee4f34b",
            "acae9ae99c4f41c3be82b87a08045fae",
            "8c767bb3c5744108be3b0dac1b1461ae",
            "f061b75f5eb94b40a1f43b68bc3a6aa3",
            "048de3858b7a4b46a1d32edf44addb06",
            "5307d752b7214b65b40ce5103aafd25b",
            "b61947090c3040a6be8a99f72c9e5400",
            "d40fd9d8c10e4cc59b21a4f1081f7a73",
            ""
          ]
        },
        "id": "c-HZv8mqGa46",
        "outputId": "332612a8-47ff-4bb6-8f2e-fc7df5bf9318",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b5cd8dcfc6a4593942acc862ee4f34b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acae9ae99c4f41c3be82b87a08045fae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c767bb3c5744108be3b0dac1b1461ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset pubmed_qa/pqa_labeled to /root/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/dd4c39f031a958c7e782595fa4dd1b1330484e8bbadd4d9212e5046f27e68924...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f061b75f5eb94b40a1f43b68bc3a6aa3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "048de3858b7a4b46a1d32edf44addb06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5307d752b7214b65b40ce5103aafd25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b61947090c3040a6be8a99f72c9e5400",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d40fd9d8c10e4cc59b21a4f1081f7a73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset pubmed_qa downloaded and prepared to /root/.cache/huggingface/datasets/pubmed_qa/pqa_labeled/1.0.0/dd4c39f031a958c7e782595fa4dd1b1330484e8bbadd4d9212e5046f27e68924. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "pubmed = load_dataset(\n",
        "    'pubmed_qa',\n",
        "    'pqa_labeled',\n",
        "    split='train'\n",
        ")\n",
        "pubmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QPH8YcsGa46",
        "outputId": "647bf232-96ae-4944-d4c3-c61ee5004b4f",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21645374,\n",
              " {'contexts': ['Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants.',\n",
              "   'The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (ΔΨm). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.'],\n",
              "  'labels': ['BACKGROUND', 'RESULTS'],\n",
              "  'meshes': ['Alismataceae',\n",
              "   'Apoptosis',\n",
              "   'Cell Differentiation',\n",
              "   'Mitochondria',\n",
              "   'Plant Leaves'],\n",
              "  'reasoning_required_pred': ['y', 'e', 's'],\n",
              "  'reasoning_free_pred': ['y', 'e', 's']})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pubmed[0]['pubid'], pubmed[0]['context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJgkH6M4Ga47",
        "outputId": "34a7f969-0f43-4fd1-d363-206a0f47e1c3",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': '21645374-0',\n",
              "  'context': 'Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature.'},\n",
              " {'id': '21645374-1',\n",
              "  'context': 'The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants. The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A.'}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "limit = 384\n",
        "\n",
        "def chunker(contexts: list):\n",
        "    chunks = []\n",
        "    all_contexts = ' '.join(contexts).split('.')\n",
        "    chunk = []\n",
        "    for context in all_contexts:\n",
        "        chunk.append(context)\n",
        "        if len(chunk) >= 3 and len('.'.join(chunk)) > limit:\n",
        "            chunks.append('.'.join(chunk).strip()+'.')\n",
        "            chunk = chunk[-2:]\n",
        "    if chunk is not None:\n",
        "        chunks.append('.'.join(chunk))\n",
        "    return chunks\n",
        "\n",
        "chunks = chunker(pubmed[0]['context']['contexts'])\n",
        "\n",
        "ids = []\n",
        "for i in range(len(chunks)):\n",
        "    ids.append(f\"{pubmed[0]['pubid']}-{i}\")\n",
        "\n",
        "data = []\n",
        "for record in pubmed:\n",
        "    chunks = chunker(record['context']['contexts'])\n",
        "    for i, context in enumerate(chunks):\n",
        "        data.append({\n",
        "            'id': f\"{record['pubid']}-{i}\",\n",
        "            'context': context\n",
        "        })\n",
        "\n",
        "data[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fMnv6Uu7Ga47"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W97u5M8yGa47"
      },
      "source": [
        "### Dense Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "import numpy as np\n",
        "from sagemaker.huggingface import HuggingFaceModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYPUvxsKGa48",
        "tags": []
      },
      "outputs": [],
      "source": [
        "role = sagemaker.get_execution_role()\n",
        "\n",
        "hub_config = {\n",
        "    'HF_MODEL_ID': 'sentence-transformers/all-MiniLM-L6-v2',\n",
        "    'HF_TASK': 'feature-extraction'\n",
        "}\n",
        "\n",
        "huggingface_model = HuggingFaceModel(\n",
        "    env=hub_config,\n",
        "    role=role,\n",
        "    transformers_version=\"4.6\",\n",
        "    pytorch_version=\"1.7\",\n",
        "    py_version=\"py36\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecibgL9RGa48",
        "outputId": "17c2d83e-47b6-4b7e-b07b-d03ef6372e5a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----!"
          ]
        }
      ],
      "source": [
        "encoder = huggingface_model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=\"ml.t2.large\",\n",
        "    endpoint_name=\"minilm-demo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2sJSUo8Ga49",
        "tags": []
      },
      "outputs": [],
      "source": [
        "out = encoder.predict({\"inputs\": [\"some text here\", \"some more text goes here too\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxS9Ohp0Ga49",
        "outputId": "8aed493e-4a03-4dd4-b63e-d2690b3bd11f",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(out[0][0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rVaNLEKQGa49"
      },
      "source": [
        "### Sparse Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR7N8LhIGa49",
        "outputId": "567328e0-e1ab-469f-e294-23ce7e7ca747",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m644.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.7.1)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
            "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.41.1)\n",
            "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU git+https://github.com/naver/splade.git\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6ApVA0pGa4-",
        "outputId": "9d4b2e63-5643-4620-c331-3e2d93b4e423",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========\n",
            "WARNING: You are not running on GPU so this may be slow.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print(\"==========\\n\"+\n",
        "          \"WARNING: You are not running on GPU so this may be slow.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "94bead89281f463581feb1e406c6c9a8",
            "9d3fed9713844ba8a758bc1c5be35b3d",
            "d080754a4edd421b8b2ff1bba46220a3",
            "ba829c7ff8224179acc1b89156180112",
            "f1efcedbde39461b81abf64c616c801f",
            "531da484a94543c5850f8f23ad03a759"
          ]
        },
        "id": "IY6S9TXoGa4-",
        "outputId": "cf8d5ffe-1e78-4ba2-b139-661ceb945e0b",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94bead89281f463581feb1e406c6c9a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d3fed9713844ba8a758bc1c5be35b3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d080754a4edd421b8b2ff1bba46220a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba829c7ff8224179acc1b89156180112",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1efcedbde39461b81abf64c616c801f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531da484a94543c5850f8f23ad03a759",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from splade.models.transformer_rep import Splade\n",
        "\n",
        "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
        "\n",
        "sparse_model = Splade(sparse_model_id, agg='max')\n",
        "sparse_model.to(device)\n",
        "sparse_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKIWiq6vGa4_",
        "outputId": "18aafa2e-ad76-47d7-955c-a5c6707c53fc",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([30522])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)\n",
        "tokens = tokenizer(data[0]['context'], return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "    sparse_emb = sparse_model(\n",
        "        d_kwargs=tokens.to(device)\n",
        "    )['d_rep'].squeeze()\n",
        "sparse_emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgZDcVmqGa4_",
        "outputId": "216bf907-592d-4e15-a15c-9e3d013b2f60",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "174\n"
          ]
        }
      ],
      "source": [
        "indices = sparse_emb.nonzero().squeeze().cpu().tolist()\n",
        "print(len(indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urnYIRtlGa5A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "values = sparse_emb[indices].cpu().tolist()\n",
        "sparse = {'indices': indices, 'values': values}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C3uZYvDYGa5A"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEo6CL7nGa5A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "def builder(records: list):\n",
        "    ids = [x['id'] for x in records]\n",
        "    contexts = [x['context'] for x in records]\n",
        "    dense_contexts = {\"inputs\": contexts}\n",
        "    dense_embeddings = encoder.predict(dense_contexts)\n",
        "    dense_vecs = np.mean(np.array(dense_embeddings), axis=1)\n",
        "    dense_vecs = dense_vecs.tolist()\n",
        "    input_ids = tokenizer(\n",
        "        contexts, return_tensors='pt',\n",
        "        padding=True, truncation=True\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        sparse_vecs = sparse_model(\n",
        "            d_kwargs=input_ids.to(device)\n",
        "        )['d_rep'].squeeze()\n",
        "    upserts = []\n",
        "    for _id, dense_vec, sparse_vec, context in zip(ids, dense_vecs, sparse_vecs, contexts):\n",
        "        indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
        "        values = sparse_vec[indices].cpu().tolist()\n",
        "        sparse_values = {\n",
        "            \"indices\": indices,\n",
        "            \"values\": values\n",
        "        }\n",
        "        metadata = {'context': context}\n",
        "        upserts.append({\n",
        "            'id': _id,\n",
        "            'values': dense_vec,\n",
        "            'sparse_values': sparse_values,\n",
        "            'metadata': metadata\n",
        "        })\n",
        "    return upserts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lCINVLCGa5B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from creds import creds\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=creds['PINECONE_API_KEY'],\n",
        "    environment=creds['PINECONE_ENV']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDlSO1h2Ga5B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "index_name = 'pubmed-splade'\n",
        "\n",
        "pinecone.create_index(\n",
        "    index_name,\n",
        "    dimension=384,\n",
        "    metric=\"dotproduct\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CCztPdiGa5B",
        "outputId": "876a6640-d865-4b9b-cca6-71ffbff8a647",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['pubmed-splade']"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pinecone.list_indexes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_caher7Ga5B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cab677cf57854636aa3647fdb36d45ba"
          ]
        },
        "id": "B0yAaHf9Ga5C",
        "outputId": "13cecfb4-6117-42b7-d2d3-0686429c8bae",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab677cf57854636aa3647fdb36d45ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "batch_size = 2\n",
        "for i in tqdm(range(0, 1000, batch_size)):\n",
        "    index.upsert(builder(data[i:i+batch_size]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXE_4Ts1Ga5C",
        "outputId": "79da7d54-1e26-43e4-fb02-1508b5c23be0",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 1000}},\n",
              " 'total_vector_count': 1000}"
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_TGh7DGa5C",
        "tags": []
      },
      "source": [
        "## Combine the retrieved documents, prompt, and question to query the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-VZ3cTQGa5D",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def encode(text: str):\n",
        "    dense_embeddings = encoder.predict({\"inputs\": [text]})\n",
        "    dense_vec = np.mean(np.array(dense_embeddings), axis=1)\n",
        "    dense_vec = dense_vec.tolist()\n",
        "    input_ids = tokenizer(text, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        sparse_vec = sparse_model(\n",
        "            d_kwargs=input_ids.to(device)\n",
        "        )['d_rep'].squeeze()\n",
        "    indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
        "    values = sparse_vec[indices].cpu().tolist()\n",
        "    sparse_dict = {\"indices\": indices, \"values\": values}\n",
        "    return dense_vec, sparse_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftY7qt3WGa5D",
        "outputId": "8dc6c5c4-6e55-4805-becf-56dbe897a3bd",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': '21645374-0',\n",
              "              'metadata': {'context': 'Programmed cell death (PCD) is the '\n",
              "                                      'regulated death of cells within an '\n",
              "                                      'organism. The lace plant (Aponogeton '\n",
              "                                      'madagascariensis) produces perforations '\n",
              "                                      'in its leaves through PCD. The leaves '\n",
              "                                      'of the plant consist of a latticework '\n",
              "                                      'of longitudinal and transverse veins '\n",
              "                                      'enclosing areoles. PCD occurs in the '\n",
              "                                      'cells at the center of these areoles '\n",
              "                                      'and progresses outwards, stopping '\n",
              "                                      'approximately five cells from the '\n",
              "                                      'vasculature.'},\n",
              "              'score': 40.5750847,\n",
              "              'values': []},\n",
              "             {'id': '21645374-6',\n",
              "              'metadata': {'context': ' The possible importance of '\n",
              "                                      'mitochondrial permeability transition '\n",
              "                                      'pore (PTP) formation during PCD was '\n",
              "                                      'indirectly examined via in vivo '\n",
              "                                      'cyclosporine A (CsA) treatment. This '\n",
              "                                      'treatment resulted in lace plant leaves '\n",
              "                                      'with a significantly lower number of '\n",
              "                                      'perforations compared to controls, and '\n",
              "                                      'that displayed mitochondrial dynamics '\n",
              "                                      'similar to that of non-PCD cells.'},\n",
              "              'score': 31.8848515,\n",
              "              'values': []}],\n",
              " 'namespace': ''}"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"Which lace plant produces perforations in its leaves through PCD?\"\n",
        "dense, sparse = encode(question)\n",
        "xc = index.query(\n",
        "    vector=dense,\n",
        "    sparse_vector=sparse,\n",
        "    top_k=2,\n",
        "    include_metadata=True\n",
        ")\n",
        "xc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu5tEG1TGa5D",
        "outputId": "d6548f99-29e7-47c8-e7c4-0413604fa3c5",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature.  The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.'"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_str = xc['matches'][0]['metadata']['context'] + ' ' + xc['matches'][1]['metadata']['context']\n",
        "context_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kCj8fWNGa5D",
        "outputId": "867c0b81-e685-4342-9f36-79b995e374bf",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Input]: Which lace plant produces perforations in its leaves through PCD?\n",
            "[Output]: Aponogeton madagascariensis\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
        "\n",
        "payload = create_payload(text_input)\n",
        "generated_text = query_llama2_7b_endpoint(payload)\n",
        "print(f\"[Input]: {question}\\n[Output]: {generated_text}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQdiRhCGa5D"
      },
      "source": [
        "## End to End RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpVI3MJoGa5E",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def rag_query(question: str) -> str:\n",
        "    dense, sparse = encode(question)\n",
        "    xc = index.query(\n",
        "        vector=dense,\n",
        "        sparse_vector=sparse,\n",
        "        top_k=2,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    context_str = xc['matches'][0]['metadata']['context'] + ' ' + xc['matches'][1]['metadata']['context']\n",
        "    text_input = prompt_template.replace(\"{context}\", context_str).replace(\"{question}\", question)\n",
        "    payload = create_payload(text_input)\n",
        "    generated_text = query_llama2_7b_endpoint(payload)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTjUwDi0Ga5E",
        "outputId": "14f6045a-8124-4712-9c05-41a66d74e607",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A. Aponogeton madagascari'"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_query(\"Which lace plant produces perforations in its leaves through PCD?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m0HAq-xGa5E",
        "outputId": "872c316e-bcd0-4bfc-f73c-7740d3767053",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes\\n\\n### 1.3.'"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_query(\"Is trabecular bone related to primary stability of miniscrews?\")"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
